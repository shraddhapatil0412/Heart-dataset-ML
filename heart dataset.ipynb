{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load dataset\n",
    "df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display first 5 records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many samples\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistical operation\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to checl duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove duplicate value\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to checl duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKfklEQVR4nO3df+ztBV3H8dcbL85Z6aB7KQRvtzVxYNKMO5LK1WpzZCuUVuaiWJpUUyet3Fxr1WqUqVlk/kMD0Wg6FlYUJmOscA1L7m0SF5jlXBqTCSibLIwf8u6P7+Ht9XKBw4FzD9z7eGzffc/5fD7nnPcf332f+5zP53NOdXcAIEmO2vQAADx9iAIAQxQAGKIAwBAFAMa2TQ/wZGzfvr137dq16TEAnlH27t17V3fvONi6Z3QUdu3alT179mx6DIBnlKr63KOt8/YRAEMUABiiAMAQBQCGKAAwRAGAsbYoVNULq+qfqurWqrq5qt66WH5sVV1TVf+1+H3Mfo85tao+sdj+pqp6zrrmA+CR1rmn8GCSX+/uk5O8PMmbquqUJG9Pcm13vyjJtYv7qaptSS5L8ivd/ZIkP5zkgTXOB8AB1haF7r69u/99cfueJLcmOSHJWUk+sNjsA0levbj9yiT/0d03Lh7zpe7+2rrmA+CRDskVzVW1K8nLkvxbkm/r7tuTrXBU1XGLzU5K0lV1dZIdST7c3e88yHOdl+S8JNm5c+chmB424/O/99JNj8DT0M7fvmmtz7/2A81V9c1Jrkhyfnd/5TE23ZbkB5P83OL3a6rqRw/cqLsv6u7d3b17x46DfnQHACtaaxSq6uhsBeGvuvsji8VfrKrjF+uPT3LHYvltSa7r7ru6+94kH03yveucD4BvtM6zjyrJxUlu7e737LfqyiTnLm6fm+TvFrevTnJqVT13cdD5h5Lcsq75AHikdR5T+IEkP5/kpqr61GLZbyZ5R5LLq+oNST6f5KeTpLvvrqr3JLkhSSf5aHdftcb5ADjA2qLQ3f+SpB5l9SOOFSwec1m2TksFYANc0QzAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAWCoKVXXtMssAeGbb9lgrq+o5SZ6bZHtVHZOkFquel+QFa54NgEPsMaOQ5JeTnJ+tAOzN16PwlSTvW99YAGzCY0ahuy9McmFVvaW733uIZgJgQx5vTyFJ0t3vrarvT7Jr/8d09wfXNBcAG7BUFKrqL5N8V5JPJfnaYnEnEQWAw8hSUUiyO8kp3d3rHAaAzVr2OoV9Sb59nYMAsHnL7ilsT3JLVX0yyX0PL+zun1zLVABsxLJR+N11DgHA08OyZx9dt+5BANi8Zc8+uidbZxslybOTHJ3kf7v7eesaDIBDb9k9hW/Z/35VvTrJ6esYCIDNWelTUrv7b5P8yFM7CgCbtuzbR2fvd/eobF234JoFgMPMsmcf/cR+tx9M8t9JznrKpwFgo5Y9pvCL6x4EgM1b9kt2Tqyqv6mqO6rqi1V1RVWduO7hADi0lj3Q/P4kV2brexVOSPL3i2UAHEaWjcKO7n5/dz+4+Lk0yY41zgXABiwbhbuq6pyqetbi55wkX1r1RavqrVW1r6purqrz91v+lqr69GL5O1d9fgBWs+zZR69P8udJ/iRbp6Jen2Slg89V9d1J3piti9/uT/KxqroqyYnZOqPp1O6+r6qOW+X5AVjdslH4/STndvfdSVJVxyZ5d7Zi8USdnORfu/vexXNdl+Q12br24R3dfV+SdPcdKzw3AE/CslE49eEgJEl3f7mqXrbia+5LckFVfWuSryZ5VZI9SU5K8oqquiDJ/yX5je6+4cAHV9V5Sc5Lkp07d644wted9jZfHscj7X3XL2x6BNiIZY8pHFVVxzx8Z7GnsGxQvkF335rkj5Jck+RjSW7M1gVx25Ick+TlSd6W5PKqqoM8/qLu3t3du3fscKwb4Km07D/2P05yfVX9dbaOKfxMkgtWfdHuvjjJxUlSVX+Q5LZsva30kcVXfn6yqh7K1pf73Lnq6wDwxCx7RfMHq2pPtj4Er5Kc3d23rPqiVXVcd99RVTuTnJ3kjCQPLZ7/n6vqpGx9RPddq74GAE/c0m8BLSKwcggOcMXimMIDSd7U3XdX1SVJLqmqfdk6K+ncxV4DAIfISscFnqzufsVBlt2f5JwNjAPAwkrfpwDA4UkUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMAQBQCGKAAwRAGAIQoADFEAYIgCAEMUABiiAMCo7t70DCurqjuTfG7TcxxGtie5a9NDwEH423xqfUd37zjYimd0FHhqVdWe7t696TngQP42Dx1vHwEwRAGAIQrs76JNDwCPwt/mIeKYAgDDngIAQxQAGKJAqurMqvp0VX2mqt6+6XngYVV1SVXdUVX7Nj3LkUIUjnBV9awk70vyY0lOSfK6qjpls1PBuDTJmZse4kgiCpye5DPd/dnuvj/Jh5OcteGZIEnS3R9P8uVNz3EkEQVOSPI/+92/bbEMOAKJAnWQZc5ThiOUKHBbkhfud//EJF/Y0CzAhokCNyR5UVV9Z1U9O8nPJrlywzMBGyIKR7jufjDJm5NcneTWJJd3982bnQq2VNWHknwiyYur6raqesOmZzrc+ZgLAIY9BQCGKAAwRAGAIQoADFEAYIgCAEMUABiiACuqqm+qqquq6saq2ldVr62q06rquqraW1VXV9XxVfX8xfdVvHjxuA9V1Rs3PT8czLZNDwDPYGcm+UJ3/3iSVNXzk/xjkrO6+86qem2SC7r79VX15iSXVtWFSY7p7r/Y3Njw6FzRDCuqqpOy9fEglyf5hyR3J7k+yWcXmzwrye3d/crF9hcl+akk39Pdtx36ieHx2VOAFXX3f1bVaUleleQPk1yT5ObuPuPAbavqqCQnJ/lqkmOz9em08LTjmAKsqKpekOTe7r4sybuTfF+SHVV1xmL90VX1ksXmv5atDxx8XZJLquroTcwMj8eeAqzupUneVVUPJXkgya8meTDJny2OL2xL8qdV9UCSX0pyenffU1UfT/JbSX5nQ3PDo3JMAYDh7SMAhigAMEQBgCEKAAxRAGCIAgBDFAAY/w8aJhG9e4MX5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#how many samples are males and females\n",
    "#male means 1 and female means 0\n",
    "#sex: discrete means categorical datatype, use countplot()\n",
    "sb.countplot(data=df,x='sex')\n",
    "y=df['sex'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(data=df,x='cp')\n",
    "y=df['cp'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(data=df,x='target')\n",
    "y=df['cp'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAK6UlEQVR4nO3df+ztBV3H8ddbL0igBu7e1ZCutzlloyQcd2gum7C1UU1hoi6S4cyF5nSrTZbNppSjtaQ5Z/QHW4C0hVMyf7BZrVZRlpN7zR+gsozEWNYNKRFKEXn3x/fct9/u7r2cAed7uPc+Htt395zP55zzfX+37/0+9zmfH6e6OwCQJE9a9wAAPHGIAgBDFAAYogDAEAUAxrZ1D/BYbN++vXft2rXuMQCOKHv37r2nu3ccbN0RHYVdu3Zlz5496x4D4IhSVXcdap23jwAYogDAEAUAhigAMEQBgCEKAIyVRaGqrq2qfVV12wHL31xVd1TV7VX1Owes21lV91fVW1Y1FwCHtsotheuTnL95QVWdm+SCJGd2948kueqA57w7ycdXOBMAh7Gyk9e6+5aq2nXA4l9K8tvd/e3FY/btX1FVFya5M8kDq5oJgMPb6jOan5vkxVV1ZZJvJXlLd99aVScl+dUkP5XksG8dVdVlSS5Lkp07d654XFifr/7m89Y9Ak9AO9/++ZW+/lbvaN6W5JQkL0xyeZIPVFUl+Y0k7+7u+x/pBbr7mu7e3d27d+w46KU7AHiUtnpL4e4kH+qNzwD9VFU9nGR7khckecVix/PJSR6uqm919+9t8XwAx7StjsKHk5yX5K+r6rlJjk9yT3e/eP8DquqKJPcLAsDWW1kUqurGJC9Jsr2q7k7yjiTXJrl2cZjqg0les9hqAOAJYJVHH118iFWXPMLzrnj8pwFgGc5oBmCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgLGyKFTVtVW1r6pu27TsnVX1uar6TFX9eVWdulh+XFW9r6o+X1VfrKpfW9VcABzaKrcUrk9y/gHL3tXdZ3b3WUluTvL2xfJXJnlKdz8vydlJXl9Vu1Y4GwAHsbIodPctSe49YNl9m+6elKT3r0pyUlVtS/J9SR5MsvmxAGyBbVv9DavqyiSXJvlGknMXi29KckGSryU5McmvdPe9B38FAFZly6PQ3W9L8rbFfoM3JXlHknOSfDfJqUlOSfK3VfUX3X3ngc+vqsuSXJYkO3fufMzznH35DY/5NTj67H3XpeseAdZinUcf/VGSixa3fz7Jn3b3d7p7X5JPJNl9sCd19zXdvbu7d+/YsWOLRgU4NmxpFKrqOZvuvizJlxa3v5rkvNpwUpIXbloHwBZZ2dtHVXVjkpck2V5Vd2fjbaKfqarTkzyc5K4kb1g8/Ook1yW5LUklua67P7eq2QA4uJVFobsvPsjiPzjEY+/PxmGpAKyRM5oBGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGEtFoar+cpllABzZth1uZVWdkOTEJNur6pQktVj19CSnrng2ALbYYaOQ5PVJfjkbAdib70XhviRXr24sANbhsFHo7vckeU9Vvbm737tFMwGwJo+0pZAk6e73VtWLkuza/JzuvmFFcwGwBktFoar+MMmzk3wmyXcXizuJKAAcRZaKQpLdSc7o7l7lMACs17LnKdyW5AdXOQgA67fslsL2JF+oqk8l+fb+hd39spVMBcBaLBuFK1Y5BABPDMseffQ3qx4EgPVb9uijb2bjaKMkOT7JcUke6O6nr2owALbeslsKT9t8v6ouTHLOKgYCYH0e1VVSu/vDSc57fEcBYN2Wffvo5ZvuPikb5y04ZwHgKLPs0Ucv3XT7oSRfSXLB4z4NAGu17D6F1656EADWb9kP2Tmtqv6kqvZV1X9U1R9X1WmrHg6ArbXsjubrknw0G5+r8MwkH1ssA+AosmwUdnT3dd390OLr+iQ7VjgXAGuwbBTuqapLqurJi69Lknx9lYMBsPWWjcIvJHlVkn9P8rUkr0hi5zPAUWbZQ1LfmeQ13f1fSVJVz0hyVTZiAcBRYtkthTP3ByFJuvveJM9fzUgArMuyUXhSVZ2y/85iS2HZrQwAjhDL/mH/3SR/X1U3ZePyFq9KcuXKpgJgLZY9o/mGqtqTjYvgVZKXd/cXVjoZAFtu6beAFhEQAoCj2KO6dDYARydRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAY1d3rnuFRq6r/THLXuuc4imxPcs+6h4CD8Lv5+HpWd+842IojOgo8vqpqT3fvXvcccCC/m1vH20cADFEAYIgCm12z7gHgEPxubhH7FAAYthQAGKIAwBAFUlXnV9UdVfXlqnrruueB/arq2qraV1W3rXuWY4UoHOOq6slJrk7y00nOSHJxVZ2x3qlgXJ/k/HUPcSwRBc5J8uXuvrO7H0zy/iQXrHkmSJJ09y1J7l33HMcSUeCZSf510/27F8uAY5AoUAdZ5jhlOEaJAncn+aFN909L8m9rmgVYM1Hg1iTPqaofrqrjk/xcko+ueSZgTUThGNfdDyV5U5I/S/LFJB/o7tvXOxVsqKobk/xDktOr6u6qet26ZzraucwFAMOWAgBDFAAYogDAEAUAhigAMEQBDqOqTq6qN27B97nQhQh5IhAFOLyTkywdhdrwaP5fXZiNq9TCWjlPAQ6jqvZfNfaOJH+V5MwkpyQ5Lsmvd/dHqmpXko8v1v94Nv7AX5rk1dm42OA9SfZ291VV9exsXKp8R5L/SfKLSZ6R5OYk31h8XdTd/7xFPyL8P9vWPQA8wb01yY9291lVtS3Jid19X1VtT/LJqtp/SZDTk7y2u99YVbuTXJTk+dn4P/bpJHsXj7smyRu6+5+q6gVJfr+7z1u8zs3dfdNW/nBwIFGA5VWS36qqn0zycDYuMf4Di3V3dfcnF7d/IslHuvt/k6SqPrb496lJXpTkg1VzcdqnbNHssBRRgOW9Ohtv+5zd3d+pqq8kOWGx7oFNjzvY5ciTjX14/93dZ61sQniM7GiGw/tmkqctbn9/kn2LIJyb5FmHeM7fJXlpVZ2w2Dr42STp7vuS/EtVvTKZndI/dpDvA2sjCnAY3f31JJ9YfHD8WUl2V9WebGw1fOkQz7k1G5cf/2ySDyXZk40dyFk873VV9dkkt+d7H336/iSXV9U/LnZGw1o4+ghWoKqe2t33V9WJSW5Jcll3f3rdc8EjsU8BVuOaxcloJyR5nyBwpLClAMCwTwGAIQoADFEAYIgCAEMUABj/B2fnJCAEKpU0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    164\n",
      "0    138\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#here output variable: target\n",
    "#how many samples for heart related patient and \n",
    "#how many samples for no heart related patiesnts\n",
    "sb.countplot(data=df,x='target')\n",
    "y=df['target'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output\n",
    "x=df.drop(\"target\",axis=1)  #input\n",
    "y=df[\"target\"]  #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((211, 13), (211,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91, 13), (91,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply StandardScaler on x_train and x_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#create object of StandardScaler class\n",
    "ss=StandardScaler()\n",
    "x_train=ss.fit_transform(x_train)\n",
    "x_test=ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06167727, -1.55023411,  1.02938967, ..., -0.69616283,\n",
       "         0.27995117, -0.51005185],\n",
       "       [ 0.43317242,  0.64506386, -0.92737808, ...,  0.95429062,\n",
       "        -0.72123014,  1.12056846],\n",
       "       [ 0.43317242, -1.55023411, -0.92737808, ..., -0.69616283,\n",
       "         1.28113248, -2.14067216],\n",
       "       ...,\n",
       "       [-2.66330193,  0.64506386,  0.05100579, ...,  0.95429062,\n",
       "        -0.72123014, -0.51005185],\n",
       "       [ 0.43317242,  0.64506386, -0.92737808, ...,  0.95429062,\n",
       "         1.28113248,  1.12056846],\n",
       "       [ 0.00607251,  0.64506386,  1.02938967, ...,  0.95429062,\n",
       "        -0.72123014,  1.12056846]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64672238,  0.64506386, -0.92737808, ..., -0.69616283,\n",
       "         1.28113248,  1.12056846],\n",
       "       [ 0.00607251, -1.55023411,  1.02938967, ..., -0.69616283,\n",
       "        -0.72123014, -0.51005185],\n",
       "       [-1.70232713,  0.64506386,  1.02938967, ...,  0.95429062,\n",
       "         3.2834951 , -0.51005185],\n",
       "       ...,\n",
       "       [-0.31425242,  0.64506386,  2.00777354, ...,  0.95429062,\n",
       "         0.27995117, -0.51005185],\n",
       "       [-1.06167727,  0.64506386, -0.92737808, ...,  0.95429062,\n",
       "         0.27995117, -0.51005185],\n",
       "       [ 1.07382229,  0.64506386, -0.92737808, ..., -0.69616283,\n",
       "         0.27995117,  1.12056846]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user define function\n",
    "def create_model(model):\n",
    "    model.fit(x_train,y_train)   #train the model with 70% data\n",
    "    y_pred=model.predict(x_test)  #model test with 30% data\n",
    "    #generate report\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform base model means logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LogisticRegression class\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78        38\n",
      "           1       0.85      0.83      0.84        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "[[30  8]\n",
      " [ 9 44]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform decision tree classifier with gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give dataset in DecisionTreeClassifier algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of class DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(random_state=1)   #bydefault GINI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model with 70% data, use fit() \n",
    "dtc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71        38\n",
      "           1       0.82      0.70      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.74      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[30  8]\n",
      " [16 37]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.317338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.113529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.113295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.088533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>0.085167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.081387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.073287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.061444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.045681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.020339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.317338\n",
       "1       chol  0.113529\n",
       "2         ca  0.113295\n",
       "3       thal  0.088533\n",
       "4        age  0.085167\n",
       "5      exang  0.081387\n",
       "6    thalach  0.073287\n",
       "7    oldpeak  0.061444\n",
       "8   trestbps  0.045681\n",
       "9        sex  0.020339\n",
       "10       fbs  0.000000\n",
       "11   restecg  0.000000\n",
       "12     slope  0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df1=pd.DataFrame(dict)\n",
    "df1.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply purining technique(max depth and min sample leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66        38\n",
      "           1       0.77      0.68      0.72        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.69      0.69      0.69        91\n",
      "weighted avg       0.70      0.69      0.69        91\n",
      "\n",
      "[[27 11]\n",
      " [17 36]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        38\n",
      "           1       0.76      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.72      0.73      0.72        91\n",
      "\n",
      "[[25 13]\n",
      " [12 41]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68        38\n",
      "           1       0.80      0.62      0.70        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.70      0.71      0.69        91\n",
      "weighted avg       0.72      0.69      0.69        91\n",
      "\n",
      "[[30  8]\n",
      " [20 33]]\n"
     ]
    }
   ],
   "source": [
    "#Pruning Technique : max_depth  : the value of max_depth cannot more than\n",
    "#8  (means <=8) \n",
    "#create object of DecisionTreeClassifier class with gini index and \n",
    "#use parameter max_depth (to remove overfitting)\n",
    "\n",
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    dtc1=DecisionTreeClassifier(random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "dtc1=DecisionTreeClassifier(random_state=1,max_depth=3) #bydefault gini\n",
    "#call function \n",
    "dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.513685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.159350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.131743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.084076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>0.047148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.041540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.022457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.513685\n",
       "1         ca  0.159350\n",
       "2      exang  0.131743\n",
       "3    oldpeak  0.084076\n",
       "4        age  0.047148\n",
       "5       chol  0.041540\n",
       "6   trestbps  0.022457\n",
       "7        sex  0.000000\n",
       "8        fbs  0.000000\n",
       "9    restecg  0.000000\n",
       "10   thalach  0.000000\n",
       "11     slope  0.000000\n",
       "12      thal  0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc1.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples leaf:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "#use 2nd purning technique : min_samples_leaf inbuilt parameter of \n",
    "#DecisionTreeClassifier class, it is class used to remove overfitting\n",
    "#leaf meand no child\n",
    "#create object for DesicionTreeClassifier class\n",
    "for i in range(45,101,1):\n",
    "    dtc2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    #by default gini index\n",
    "    print(\"min samples leaf: \",i)\n",
    "    #call function\n",
    "    dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "dtc2=DecisionTreeClassifier(random_state=1,min_samples_leaf=45)\n",
    "dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.704874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.218659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.076467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.704874\n",
       "1         ca  0.218659\n",
       "2        age  0.076467\n",
       "3        sex  0.000000\n",
       "4   trestbps  0.000000\n",
       "5       chol  0.000000\n",
       "6        fbs  0.000000\n",
       "7    restecg  0.000000\n",
       "8    thalach  0.000000\n",
       "9      exang  0.000000\n",
       "10   oldpeak  0.000000\n",
       "11     slope  0.000000\n",
       "12      thal  0.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc2.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform decision tree classifier with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier with Entropy method\n",
    "#first create object of DecisionTreeClassifier\n",
    "dt_entropy=DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "#bydeafult criterion='gini' if not given\n",
    "#formula= -P*log(P)-Q*log(Q )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "dt_entropy=create_model(dt_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.243182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.129411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.108986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.097910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.096058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.089420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.083485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.077822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.045352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.028375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.243182\n",
       "1         ca  0.129411\n",
       "2        age  0.108986\n",
       "3       thal  0.097910\n",
       "4   trestbps  0.096058\n",
       "5    thalach  0.089420\n",
       "6       chol  0.083485\n",
       "7      exang  0.077822\n",
       "8    oldpeak  0.045352\n",
       "9        sex  0.028375\n",
       "10       fbs  0.000000\n",
       "11   restecg  0.000000\n",
       "12     slope  0.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dt_entropy.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df1=pd.DataFrame(dict)\n",
    "df1.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply purining technique(max depth and min sample leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66        38\n",
      "           1       0.77      0.68      0.72        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.69      0.69      0.69        91\n",
      "weighted avg       0.70      0.69      0.69        91\n",
      "\n",
      "[[27 11]\n",
      " [17 36]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        38\n",
      "           1       0.76      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.72      0.73      0.72        91\n",
      "\n",
      "[[25 13]\n",
      " [12 41]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68        38\n",
      "           1       0.80      0.62      0.70        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.70      0.71      0.69        91\n",
      "weighted avg       0.72      0.69      0.69        91\n",
      "\n",
      "[[30  8]\n",
      " [20 33]]\n"
     ]
    }
   ],
   "source": [
    "#Pruning Technique : max_depth  : the value of max_depth cannot more than\n",
    "#8  (means <=8) \n",
    "#create object of DecisionTreeClassifier class with gini index and \n",
    "#use parameter max_depth (to remove overfitting)\n",
    "\n",
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    dtc3=DecisionTreeClassifier(random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "dtc3=DecisionTreeClassifier(random_state=1,max_depth=3)\n",
    "dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.513685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.159350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.131743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.084076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>0.047148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.041540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.022457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.513685\n",
       "1         ca  0.159350\n",
       "2      exang  0.131743\n",
       "3    oldpeak  0.084076\n",
       "4        age  0.047148\n",
       "5       chol  0.041540\n",
       "6   trestbps  0.022457\n",
       "7        sex  0.000000\n",
       "8        fbs  0.000000\n",
       "9    restecg  0.000000\n",
       "10   thalach  0.000000\n",
       "11     slope  0.000000\n",
       "12      thal  0.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc3.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples leaf:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "min samples leaf:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "#use 2nd purning technique : min_samples_leaf inbuilt parameter of \n",
    "#DecisionTreeClassifier class, it is class used to remove overfitting\n",
    "#leaf meand no child\n",
    "#create object for DesicionTreeClassifier class\n",
    "for i in range(45,101,1):\n",
    "    dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    #by default gini index\n",
    "    print(\"min samples leaf: \",i)\n",
    "    #call function\n",
    "    dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=45)\n",
    "dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of RandomForestClassifier class\n",
    "rfc=RandomForestClassifier(n_estimators=10,random_state=1)\n",
    "#here n_estimators means take how many no. of decision tree\n",
    "#n_estimators >=10 but n_estimators<=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68        38\n",
      "           1       0.80      0.66      0.72        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.71      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[29  9]\n",
      " [18 35]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Decision Tree:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68        38\n",
      "           1       0.80      0.66      0.72        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.71      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[29  9]\n",
      " [18 35]]\n",
      "No. of Decision Tree:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No. of Decision Tree:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No. of Decision Tree:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of Decision Tree:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of Decision Tree:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of Decision Tree:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No. of Decision Tree:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No. of Decision Tree:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of Decision Tree:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No. of Decision Tree:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No. of Decision Tree:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No. of Decision Tree:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No. of Decision Tree:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        38\n",
      "           1       0.85      0.74      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.78      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[31  7]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        38\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[31  7]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        38\n",
      "           1       0.83      0.74      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.76      0.76        91\n",
      "\n",
      "[[30  8]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        38\n",
      "           1       0.83      0.74      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.76      0.76        91\n",
      "\n",
      "[[30  8]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "No. of Decision Tree:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        38\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[31  7]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No. of Decision Tree:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of Decision Tree:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No. of Decision Tree:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No. of Decision Tree:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision Tree:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101,1):\n",
    "    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Decision Tree: \",i)\n",
    "    #call function\n",
    "    rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=25,random_state=1)\n",
    "#by default gini index\n",
    "#call function\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.190503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.155793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.104839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.092591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.076090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>0.071090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.067548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.062051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.058885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.052457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.033204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.021113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.013836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.190503\n",
       "1    thalach  0.155793\n",
       "2       thal  0.104839\n",
       "3    oldpeak  0.092591\n",
       "4         ca  0.076090\n",
       "5        age  0.071090\n",
       "6   trestbps  0.067548\n",
       "7      slope  0.062051\n",
       "8       chol  0.058885\n",
       "9      exang  0.052457\n",
       "10       sex  0.033204\n",
       "11   restecg  0.021113\n",
       "12       fbs  0.013836"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':rfc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df3=pd.DataFrame(dict)\n",
    "df3.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68        38\n",
      "           1       0.80      0.66      0.72        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.71      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[29  9]\n",
      " [18 35]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71        38\n",
      "           1       0.82      0.70      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.74      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[30  8]\n",
      " [16 37]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n"
     ]
    }
   ],
   "source": [
    "#use purning technique \n",
    "#max-depth\n",
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    rfc1=RandomForestClassifier(n_estimators=25,random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    rfc1=create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "rfc1=RandomForestClassifier(n_estimators=25,random_state=1,max_depth=2)\n",
    "rfc1=create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.240697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.178520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.158538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.105390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.098428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.082175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.073648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.024933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>age</td>\n",
       "      <td>0.023987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.009222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.002841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.240697\n",
       "1    thalach  0.178520\n",
       "2       thal  0.158538\n",
       "3    oldpeak  0.105390\n",
       "4      slope  0.098428\n",
       "5      exang  0.082175\n",
       "6         ca  0.073648\n",
       "7        sex  0.024933\n",
       "8        age  0.023987\n",
       "9       chol  0.009222\n",
       "10  trestbps  0.002841\n",
       "11   restecg  0.001621\n",
       "12       fbs  0.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':rfc1.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df4=pd.DataFrame(dict)\n",
    "df4.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min sample value :  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "min sample value :  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "min sample value :  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "min sample value :  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "min sample value :  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "min sample value :  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "min sample value :  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "min sample value :  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "min sample value :  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        38\n",
      "           1       0.79      0.79      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[27 11]\n",
      " [11 42]]\n",
      "min sample value :  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "min sample value :  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "min sample value :  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "min sample value :  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "min sample value :  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "min sample value :  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "min sample value :  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "min sample value :  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "min sample value :  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "min sample value :  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "min sample value :  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "min sample value :  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "min sample value :  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "min sample value :  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "min sample value :  68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57        38\n",
      "           1       0.69      0.81      0.75        53\n",
      "\n",
      "    accuracy                           0.68        91\n",
      "   macro avg       0.67      0.66      0.66        91\n",
      "weighted avg       0.68      0.68      0.67        91\n",
      "\n",
      "[[19 19]\n",
      " [10 43]]\n",
      "min sample value :  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "min sample value :  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(45,101,1):\n",
    "    rfc2=RandomForestClassifier(n_estimators=25,random_state=1,min_samples_leaf=i) #bydefault gini\n",
    "    print(\"min sample value : \",i)\n",
    "    #call function \n",
    "    rfc2=create_model(rfc2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply ensembling technique boosting\n",
    "#1. first apply ADA boost: call inbuilt class AdaBoostClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302, 13)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Decision stump:  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "No. of Decision stump:  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71        38\n",
      "           1       0.88      0.55      0.67        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.73      0.72      0.69        91\n",
      "weighted avg       0.76      0.69      0.69        91\n",
      "\n",
      "[[34  4]\n",
      " [24 29]]\n",
      "No. of Decision stump:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "No. of Decision stump:  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        38\n",
      "           1       0.79      0.79      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[27 11]\n",
      " [11 42]]\n",
      "No. of Decision stump:  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69        38\n",
      "           1       0.78      0.79      0.79        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[26 12]\n",
      " [11 42]]\n",
      "No. of Decision stump:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        38\n",
      "           1       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[27 11]\n",
      " [10 43]]\n",
      "No. of Decision stump:  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "No. of Decision stump:  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "No. of Decision stump:  9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of Decision stump:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75        38\n",
      "           1       0.84      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.78      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[30  8]\n",
      " [12 41]]\n",
      "No. of Decision stump:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78        38\n",
      "           1       0.86      0.79      0.82        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.81      0.80      0.80        91\n",
      "\n",
      "[[31  7]\n",
      " [11 42]]\n",
      "No. of Decision stump:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77        38\n",
      "           1       0.85      0.77      0.81        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.80      0.79      0.79        91\n",
      "\n",
      "[[31  7]\n",
      " [12 41]]\n",
      "No. of Decision stump:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77        38\n",
      "           1       0.85      0.77      0.81        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.80      0.79      0.79        91\n",
      "\n",
      "[[31  7]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,14):\n",
    "    ada=AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Decision stump: \",i)\n",
    "    #call function\n",
    "    ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        38\n",
      "           1       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[27 11]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "#create the object of AdaBoostClassifier class\n",
    "#ADA Boost creates decision stump (means one root node and 2 leaf node)\n",
    "#leaf node: no any childs\n",
    "ada=AdaBoostClassifier(n_estimators=6,random_state=1)\n",
    "#n_estimators means how many decision stumps, decision stumps depend on \n",
    "#no. of input\n",
    "#in case of our dataset, no. of features means inputs=13\n",
    "#call function\n",
    "ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0        sex  0.166667\n",
       "1         cp  0.166667\n",
       "2    thalach  0.166667\n",
       "3    oldpeak  0.166667\n",
       "4      slope  0.166667\n",
       "5         ca  0.166667\n",
       "6        age  0.000000\n",
       "7   trestbps  0.000000\n",
       "8       chol  0.000000\n",
       "9        fbs  0.000000\n",
       "10   restecg  0.000000\n",
       "11     exang  0.000000\n",
       "12      thal  0.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':ada.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df=pd.DataFrame(dict)\n",
    "df.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Gradient Boosting(GB) : - \n",
    "#Its basically focus on short comings error  means fully grown tree \n",
    "#error means residual =actual output-predicted output\n",
    "\n",
    "#2. gradient Boost technuique : second tech. of Boosting Ensembling \n",
    "#technique \n",
    "# GB  : - its create a fully grown tree.this algorithm is focus on \n",
    "#short comings \n",
    "#short comings means error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class for Gradient Boosting: GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of estimators:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "No of estimators:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        38\n",
      "           1       0.81      0.81      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[28 10]\n",
      " [10 43]]\n",
      "No of estimators:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of estimators:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "No of estimators:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No of estimators:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No of estimators:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "No of estimators:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of estimators:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of estimators:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "No of estimators:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of estimators:  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No of estimators:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No of estimators:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No of estimators:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "No of estimators:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "No of estimators:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "No of estimators:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of estimators:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of estimators:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of estimators:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n"
     ]
    }
   ],
   "source": [
    "#Create the object of GradientBoostingClassifier class  and passing the \n",
    "#parameter n_estimators means how many iteration means how many\n",
    "#decisionTree use for train the model\n",
    "\n",
    "for i in range(10,101,1):\n",
    "    gbc=GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No of estimators: \",i)\n",
    "    #call function\n",
    "    gbc=create_model(gbc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        38\n",
      "           1       0.81      0.81      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[28 10]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "#Create the object of GradientBoostingClassifier class\n",
    "gbc=GradientBoostingClassifier(n_estimators=11,random_state=1)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.428971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.151844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.085778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.077987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.065412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.042441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>0.030353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.020001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.019248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.013910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.428971\n",
       "1         ca  0.151844\n",
       "2    thalach  0.085778\n",
       "3      exang  0.077987\n",
       "4       thal  0.065412\n",
       "5    oldpeak  0.064054\n",
       "6        sex  0.042441\n",
       "7        age  0.030353\n",
       "8   trestbps  0.020001\n",
       "9      slope  0.019248\n",
       "10      chol  0.013910\n",
       "11       fbs  0.000000\n",
       "12   restecg  0.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':gbc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df=pd.DataFrame(dict)\n",
    "df.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting(XGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Extreame Gradient Boosting  : 3rd technique of Boosting \n",
    "#This is better version of gradient boosting . . short form XGB \n",
    "#why call better version of Gradient Boosting : -\n",
    "#1. XG Bossting use : - Multithreading technique\n",
    "#2. It takes less memory space and faster \n",
    "#3. It is very useful to handle huge amt of data .Its deal large amount of data\n",
    "#4. Its handle outlier because have inbuilt capability\n",
    "#5. Its handle null values \n",
    "#6. Its handle automatic overfitting situation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\shra\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shra\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\shra\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "#first time install xgboost on system\n",
    "#!pip install xgboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class:XGBClassifier which definbe in package xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of estimators:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No of estimators:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of estimators:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "No of estimators:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of estimators:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of estimators:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of estimators:  32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of estimators:  35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of estimators:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67        38\n",
      "           1       0.78      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.71      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[27 11]\n",
      " [15 38]]\n",
      "No of estimators:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of estimators:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of estimators:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101,1):\n",
    "    xgc=XGBClassifier(n_estimators=i,reg_alpha=1,random_state=1)\n",
    "    print(\"No of estimators: \",i)\n",
    "    #call function\n",
    "    xgc=create_model(xgc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "#create object of XGBClassifier class\n",
    "xgc=XGBClassifier(n_estimators=10,reg_alpha=1,random_state=1)\n",
    "#reg means regularisation\n",
    "#alpha means lambda means hyper parameter\n",
    "#if reg_alpha=1, 1 means True means automatic handle outlier and overfitting\n",
    "#call function\n",
    "xgc=create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.454883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.111569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.097874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.074755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.054751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.053498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.044574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.028306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.024244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.019358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.018595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>age</td>\n",
       "      <td>0.017592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.454883\n",
       "1      exang  0.111569\n",
       "2         ca  0.097874\n",
       "3       thal  0.074755\n",
       "4    oldpeak  0.054751\n",
       "5      slope  0.053498\n",
       "6    thalach  0.044574\n",
       "7        sex  0.028306\n",
       "8   trestbps  0.024244\n",
       "9    restecg  0.019358\n",
       "10      chol  0.018595\n",
       "11       age  0.017592\n",
       "12       fbs  0.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':xgc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.428971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.151844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.085778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.077987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thal</td>\n",
       "      <td>0.065412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.042441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>0.030353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.020001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>slope</td>\n",
       "      <td>0.019248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.013910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input        IG\n",
       "0         cp  0.428971\n",
       "1         ca  0.151844\n",
       "2    thalach  0.085778\n",
       "3      exang  0.077987\n",
       "4       thal  0.065412\n",
       "5    oldpeak  0.064054\n",
       "6        sex  0.042441\n",
       "7        age  0.030353\n",
       "8   trestbps  0.020001\n",
       "9      slope  0.019248\n",
       "10      chol  0.013910\n",
       "11       fbs  0.000000\n",
       "12   restecg  0.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':gbc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df=pd.DataFrame(dict)\n",
    "df.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give data in support vector machine\n",
    "#1. Linear kernal function of svm: \n",
    "#means suppose data are linear separatable with the help of straight line\n",
    "#call inbuilt class for linear svm: LinearSVC\n",
    "#SVC means support vector classifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LinearSVC class\n",
    "svc=LinearSVC(random_state=1)  #no add nay error means suppose no outlier\n",
    "#in iur dataset means it is hard margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        38\n",
      "           1       0.83      0.83      0.83        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.80      0.80      0.80        91\n",
      "\n",
      "[[29  9]\n",
      " [ 9 44]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply KNN algorithm: inbuilt class KNeighborsClassifier which define in \n",
    "#outer class neighbors and outer class define in package sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77        38\n",
      "           1       0.84      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.80      0.80      0.80        91\n",
      "\n",
      "[[30  8]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "knc=create_model(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Naive Bayes Theorem\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#inbuilt class GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#craete object of GaussianNB class\n",
    "gnb=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77        38\n",
      "           1       0.85      0.77      0.81        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.80      0.79      0.79        91\n",
      "\n",
      "[[31  7]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "gnb=create_model(gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conclusion: In this dataset their are Support vector machine (SVC) this algorithm is predict 80% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
